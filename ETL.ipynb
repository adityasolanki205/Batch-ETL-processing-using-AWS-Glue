{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "from collections import Iterable, OrderedDict\n",
    "from itertools import product\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "#import findspark\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.column import Column, _to_java_column\n",
    "from pyspark.sql.types import array, ArrayType, IntegerType, NullType, StringType, StructType\n",
    "from pyspark.sql.functions import col, concat_ws, collect_list, explode, lit, split, when, upper\n",
    "\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue.transforms import Relationalize\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "## @params: [JOB_NAME]\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "appName = \"testing\"\n",
    "master = \"local\"\n",
    "spark = SparkSession.builder.\\\n",
    "        appName(appName).\\\n",
    "        master(master).\\\n",
    "        getOrCreate()     \n",
    "\n",
    "bucket = \"input-etl-glue\"\n",
    "spark.conf.set('temporaryGcsBucket', bucket)\n",
    "df = spark.read.option( \"inferSchema\" , \"true\" ).option(\"header\",\"true\").csv(\"s3://input-etl-glue/german_data.csv\")\n",
    "\n",
    "df = df.filter((df.Purpose != 'NULL') & (df.Existing_account != 'NULL') & (df.Property !=  'NULL') & (df.Personal_status != 'NULL') & (df.Existing_account != 'NULL')  & (df.Credit_amount != 'NULL' ) & (df.Installment_plans != 'NULL'))\n",
    "\n",
    "# Changing the Datatype of Credit Amount from string to Float\n",
    "df = df.withColumn(\"Credit_amount\", df['Credit_amount'].cast('float'))\n",
    "\n",
    "# Converting data into better readable format. Here Existing amount column is segregated into 2 columns Months and days\n",
    "split_col= pyspark.sql.functions.split(df['Existing_account'], '')\n",
    "df = df.withColumn('Month', split_col.getItem(0))\n",
    "df = df.withColumn('day1', split_col.getItem(1))\n",
    "df = df.withColumn('day2', split_col.getItem(2))\n",
    "\n",
    "df = df.withColumn('Days', sf.concat(sf.col('day1'),sf.col('day2')))\n",
    "\n",
    "# Converting data into better readable format. Here Purpose column is segregated into 2 columns File Month and Version\n",
    "split_purpose= pyspark.sql.functions.split(df['Purpose'], '')\n",
    "df = df.withColumn('File_month', split_purpose.getItem(0))\n",
    "df = df.withColumn('ver1', split_purpose.getItem(1))\n",
    "df = df.withColumn('ver2', split_purpose.getItem(2))\n",
    "\n",
    "df=df.withColumn('Version', sf.concat(sf.col('ver1'),sf.col('ver2')))\n",
    "\n",
    "Month_Dict = {\n",
    "    'A':'January',\n",
    "    'B':'February',\n",
    "    'C':'March',\n",
    "    'D':'April',\n",
    "    'E':'May',\n",
    "    'F':'June',\n",
    "    'G':'July',\n",
    "    'H':'August',\n",
    "    'I':'September',\n",
    "    'J':'October',\n",
    "    'K':'November',\n",
    "    'L':'December'\n",
    "    }\n",
    "\n",
    "df= df.replace(Month_Dict,subset=['File_month'])\n",
    "df = df.replace(Month_Dict,subset=['Month'])\n",
    "\n",
    "#Dropping unwanted columns from the dataframe.\n",
    "df = df.drop('day1')\n",
    "df = df.drop('day2')\n",
    "df = df.drop('ver1')\n",
    "df = df.drop('ver2')\n",
    "df = df.drop('Purpose')\n",
    "df = df.drop('Existing_account')\n",
    "\n",
    "df.write.format(\"csv\").mode(\"append\").option('header', 'true').save(\"s3://output-elt-glue/\")\n",
    "\n",
    "\n",
    "job.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
